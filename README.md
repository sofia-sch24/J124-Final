# J124-Final
## By Sofia Schnurer

dataset: https://docs.google.com/spreadsheets/d/1uBeZoFyMGG1coBuBjTrJCk-j13NVXJF6V0TOm8bHr4E/edit#gid=898543253, https://github.com/BuzzFeedNews/2016-10-facebook-fact-check

## Story Pitch and Sources

It is essential with the prevalence of social media to understand and identify disinformation and extreme content. Many experts are now advising users to excerise increased caution with content on the internet and social media in general. Facebook has shaped the 2016 election and the past 6 years through their inability to curb misinformation. In so many ways, having content without restrictions feeds into Facebook's strategy for more users and more time spent on the platform. As a OSINT researcher at the Berkeley Law Human Rights Center, I've used open source investigations to identify and verify human rights violations. In my findings, I do come across disinformation and understand the methods to verify sources but this knowledge is not widely accessible. Seeing how prevalent misinformation is across social media made me intrigued to do some data analysis on it. 

As anyone would know, misinformation is very dangerous as some content can further racism, xenophobia, sexism, homophopbia, anti-semitism, and islamophobia. Misinformation also contributes to climate change denial, anti-vaccinations, and increased partisanship. 

What intrigues me is understanding how Facebook has changed its policies and whether these policies have been effective in countering misinformation. I hope to speask with experts and facebook users on how they feel policies have changed and whether they've seen increased effectiveness in countering misinformation. I hope to write a story discussing the changes Facebook has made as a response to the Cambridge Analytica scandal and overall disinformation surrounding the 2016 election and whether these policies have been effective in countering misinformation. I hope to add testimony from leading researchers in the communications and misinformation field regarding Facebook's policies changes and the concerns these researchers have over the lack of awareness surrounding misinformation. I hope to also interview Craig Silverman, the co-author of the Buzzfeed report I based my data analysis off, to hear his observations after writing that massive report and whether he notices differences in the emergence of misinforming posts from the outlets the report studied (ex. CNN Politics, Freedom Daily, Occupy Democrats). 

## Sources

1. Professor Stephanie Edgerly- stephanie.edgerly@northwestern.edu, (847) 467-2528
Edgerly is an Associate Professor at Northwestern University studying disinformation and its effects on media. Her work focuses on how social media alters the way an audience chooses to consume news and how this impacts their political engagement. I would ask her questions regarding how the 2016 election has shaped Americans' trust in social media and if she beleives misinformation has worsened on the platform. 

2. Professor Kenneth Joseph- kjoseph@buffalo.edu, 716-645-0682
Joseph is an Assistant Professor of Computer Science and Engineering at the University of Buffalo. His expertise focuses on misinformation and politics as well as societal impacts of social media and online platforms. I would ask his questions regarding whether Facebook's new policies has effectively contributed to removing more misleading posts and steps users can take to tell if posts on Facebook are misleading, besides reviewing the source. 

3. Craig Silverman, craig.silverman@buzzfeed.com
Silverman is the founding editor of the report published by Buzzfeed and the dataset I based my work off of. Although the report is dated back to the 2016 election, I would like to ask him and contributing reporters on his team the most surpising work they found during this report. I would also ask if they have noticed marked changes in the proliferation of misinformation on Facebook today in comparison to 2016 (the year the report was written). 

### Additional Data Sources: 

1. Q2 2022 Widely Viewed Content Report by Meta, https://transparency.fb.com/data/widely-viewed-content-report/

2. "In Ukraine, Facebook fact-checkers fight a war on two fronts" by The Washington Post, https://www.washingtonpost.com/technology/2022/04/12/facebook-fact-checkers-misinformation-ukraine-war/
